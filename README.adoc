= streams-int

Example project using a REST endpoint to send messages to streams/kafka.  These messages are consumed from the kafka topic and sent to S3 and DynamoDB.  The project is based on openshift 3.11, Stream 1.3/7.5 and Fuse 7.2.

* Kafka and REST bridge found in `streams` directory
* Spring boot fuse component found in `fuse` directory.  Consumes from kafka and produces to S3 and DynamoDB.


== Install streams using the cluster operator

== Create a project
After logging into openshift (minishift: oc login -u system:admin) via the cli create a new project  and the needed secret (https://docs.openshift.com/container-platform/3.11/install_config/configuring_red_hat_registry.html)
----
oc new-project demo
----

=== Create a secret to access red hat repositories
Follow https://docs.openshift.com/container-platform/3.11/install_config/configuring_red_hat_registry.html[link] instruructions to create a secret and save it to the file `secret.yaml`.  For the purpose of this example the secret is name 'demo-kafa' which can be found in the yaml file

----
apiVersion: v1
kind: Secret
metadata:
  name: demo-kafka
----

=== Create service accounts and link secrets
----
oc create -f secret.yaml -n demo
oc create sa strimzi-cluster-operator
oc create sa my-cluster-zookeeper
oc create sa my-bridge-bridge

oc secrets link default demo-kafka --for=pull
oc secrets link builder demo-kafka

oc secret link strimzi-cluster-operator demo-kafka  --for=pull
oc secret link my-cluster-zookeeper demo-kafka  --for=pull
oc secret link my-bridge-bridge demo-kafka  --for=pull
----

=== Create the cluster operator in the kafka project/namespace
----
oc apply -f streams/install/cluster-operator -n demo
oc apply -f streams/examples/templates/cluster-operator -n demo
----

=== Install and configure kafka cluster

==== Create the kafka cluster in the name space. 
In this example we are using a single node kafka for development purposes
----
oc apply -f streams/examples/kafka/kafka-persistent-single.yaml
----

==== Create a topic (make sure the 3 zookeeper and 3 kafka pods are started)
----
oc apply -f streams/examples/topic/kafka-topic.yaml
----

=== Create the REST bridge
If you've modifid the kafka condfiguration you may need to modify the `bootstrapservers` in https://github.com/rediverson/streams-int/blob/master/streams/examples/kafka-bridge/kafka-bridge.yaml[kafka-bridge.yaml]
----
oc apply -f streams/examples/kafka-bridge/kafka-bridge.yaml
----

=== Create a node port
Create a node port based on the bridge pod.  Use first command to find the name.  `my-bridge-bridge-8466dd8859-zq4sp` is just an example of the format.
----
oc get pods -o name
oc port-forward pod/my-bridge-bridge-8466dd8859-zq4sp 8080:8080 &
----

=== Test the bridge
Use the base url of the node port followed by the `/topics/topic` to post messages to.
----
curl -X POST   http://localhost:8080/topics/my-topic   -H 'content-type: application/vnd.kafka.json.v2+json'   -d '{
    "records": [
        {
            "key": "100",
            "value": { "acct": "100", "age" : 5, "foo": "bar" }
        },
        {
            "value": { "acct": "101", "age" : 10, "foo": "bar" }
        }
    ]
}'
----

==== Verify results
The HTTP response should contain the offsets for the messages like below.
----
{"offsets":[{"partition":0,"offset":194},{"partition":0,"offset":195}]}
----

== Create the fuse component
=== Modify AWS credentials
The Fuse routes must be modified to use AWS credentials

In the file https://github.com/rediverson/streams-int/blob/master/fuse/src/main/java/rediverson/Route.java[Route.java]

* Replace twice `XXXXXXXXXX` with your AWS access Key
* Replace twice `ZZZZZZZZZZ` with your AWS secret Key
* Replace twice `Regions.US_EAST_1` with your AWS secret Key
* S3
** Replace `rediverson-bucket` with your S3 bucket
* DynamoDb
** Replace `rediverson-table` with your DynamoDB table.
** `pkey` for the partition/primary key.  Adjust as needed.
** `value` data value field. Adjust as needed.

=== Deploy the fuse application

NOTE: This step required the Red Hat repositories to be included in the maven `settings.xml` file.  Here is a sample settings https://gist.github.com/craigivy/418be6a62ab4f67e7885ade645eee7c4[file]

Build and deploy the project to the Kubernetes / OpenShift cluster:
----
cd fuse
mvn clean -DskipTests fabric8:deploy -Popenshift
----




